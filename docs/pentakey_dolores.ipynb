{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Su3pJKBp0hVw",
        "eIl1AeCj7Bob",
        "D3JVfARw7nUx",
        "QKoM6wmJ9JQo",
        "HyNN1XRY8avr",
        "bVxLnPF68bur"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This project allows you to convert the photo of a generic sheet music into MusicXML format.\n",
        "\n",
        "How does it do this?\n",
        "\n",
        "It uses a neural network that can recognize objects (in this case notes, rests, etc.) and by means of sorting algorithms and the position of the latter to do a complete sorting. Through a parser the objects are then converted into MusicXML notations.\n",
        "\n",
        "Authors:\n",
        "- Pietro Negri\n",
        "- Antonio Cacciapuoti\n",
        "- Giovanni Rapa\n",
        "\n",
        "Musimathics Lab, UNISA 2023"
      ],
      "metadata": {
        "id": "ETgciXkw5Pzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 - Mount Drive partition\n",
        "Checks on the GPU we will be using and gdrive mouting. To use CUDA you need a GPU, you have to request it on Colab (T4 GPU)."
      ],
      "metadata": {
        "id": "Su3pJKBp0hVw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FEC9VG5GFab",
        "outputId": "77e90c4b-3006-425e-c993-69859bb55e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 15 19:52:48 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Check GPU Availability\n",
        "gpu_info = !nvidia-smi  # Execute the nvidia-smi command to get GPU information\n",
        "gpu_info = '\\n'.join(gpu_info)  # Convert the GPU information into a string\n",
        "\n",
        "# Check if GPU is available\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "    print('and then re-execute this cell.')\n",
        "else:\n",
        "    print(gpu_info)\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive  # Import the drive module from the google.colab library\n",
        "drive.mount('/content/gdrive')  # Mount Google Drive to the /content/gdrive directory"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - DarkNet installation\n",
        "We need to install Darknet and OpenCv to recognize objects in scores."
      ],
      "metadata": {
        "id": "RQ0AnR7D3iHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the working directory to /content\n",
        "%cd /content\n",
        "\n",
        "# Remove the existing 'darknet' directory if it exists\n",
        "!rm -r darknet\n",
        "\n",
        "# Clone the Darknet repository\n",
        "!git clone https://github.com/AlexeyAB/darknet\n",
        "\n",
        "# Update and upgrade your system\n",
        "!apt-get update\n",
        "!apt-get upgrade\n",
        "\n",
        "# Install necessary dependencies\n",
        "!apt-get install build-essential\n",
        "!apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev\n",
        "!apt-get install libavcodec-dev libavformat-dev libswscale-dev\n",
        "!apt-get install libopencv-dev\n",
        "\n",
        "# Change the directory to the 'darknet' folder\n",
        "%cd darknet\n",
        "\n",
        "# Modify the Makefile for Darknet to enable the desired configurations\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "\n",
        "# Build Darknet\n",
        "!make\n",
        "\n",
        "# Run Darknet (replace this with your own Darknet commands)\n",
        "!./darknet"
      ],
      "metadata": {
        "id": "I6sSYKTRHHef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Set Yolo Configuration\n",
        "We need to set configurations for Yolo in order to properly train. There are few settings which we need to change in the default yolov3.cfg file.\n",
        "\n",
        "- batch\n",
        "- subdivisions (if you get memory out error, increase this 16, 32 or 64)\n",
        "- max_batches (it should be classes*2000)\n",
        "- steps (it should be 80%, 90% of max_batches)\n",
        "- classes (the number of classes which you are going to train)\n",
        "- filters (the value for filters can be calculated using (classes + 5)x3 )\n",
        "\n",
        "Change the values below as per your requirement."
      ],
      "metadata": {
        "id": "eIl1AeCj7Bob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List the contents of the current directory\n",
        "!ls\n",
        "\n",
        "# Calculate anchors for your custom dataset\n",
        "!./darknet detector calc_anchors data/obj.data -num_of_clusters 9 -width 800 -height 800 -show"
      ],
      "metadata": {
        "id": "BGBU2zrQLlFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfeEMnxilTzU"
      },
      "source": [
        "# Modify YOLOv3-SPP configuration file (yolov3-spp.cfg) using sed commands\n",
        "\n",
        "# Set batch size to 64\n",
        "!sed -i 's/batch=1/batch=64/g' cfg/yolov3-spp.cfg\n",
        "\n",
        "# Set subdivisions to 32\n",
        "!sed -i 's/subdivisions=1/subdivisions=32/g' cfg/yolov3-spp.cfg\n",
        "\n",
        "# Adjust input width and height to 800x800\n",
        "!sed -i 's/width=608/width=800/g' cfg/yolov3-spp.cfg\n",
        "!sed -i 's/height=608/height=800/g' cfg/yolov3-spp.cfg\n",
        "\n",
        "# Set max_batches to 116000\n",
        "!sed -i 's/max_batches = 500200/max_batches = 116000/g' cfg/yolov3-spp.cfg\n",
        "\n",
        "# Adjust training steps\n",
        "!sed -i 's/steps=400000,450000/steps=92800,104400/g' cfg/yolov3-spp.cfg\n",
        "\n",
        "# Set the number of classes to 58\n",
        "!sed -i 's/classes=80/classes=58/g' cfg/yolov3-spp.cfg\n",
        "\n",
        "# Adjust the number of filters to 189\n",
        "!sed -i 's/filters=255/filters=189/g' cfg/yolov3-spp.cfg\n",
        "\n",
        "# Display the modified configuration file\n",
        "!cat cfg/yolov3-spp.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Get and unzip the DataSet"
      ],
      "metadata": {
        "id": "D3JVfARw7nUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/gdrive'):\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "DOWNLOAD_LOCATION = '/content/darknet/data/'\n",
        "DRIVE_DATASET_FILE = '/content/gdrive/MyDrive/ASMC/PentaKey/mlYOLO/PentaKey_yolo.zip' # adjust path/name of dataset which is in your G-drive\n",
        "\n",
        "shutil.copy(DRIVE_DATASET_FILE, DOWNLOAD_LOCATION)\n",
        "\n",
        "# Print a success message indicating that the dataset has been successfully downloaded\n",
        "print('Successfully downloaded the dataset')"
      ],
      "metadata": {
        "id": "1Z2Q5ngtHabM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List the contents of the current directory\n",
        "!ls\n",
        "\n",
        "# Unzip the \"PentaKey_yolo.zip\" file into the \"./data\" directory\n",
        "!unzip data/PentaKey_yolo.zip -d ./data"
      ],
      "metadata": {
        "id": "lcYP0_TCJyMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4 - Download initial pre-trained weights for the convolutional layers (If you have already trained and saved the weights to your Google drive, you can skip this)"
      ],
      "metadata": {
        "id": "QKoM6wmJ9JQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the darknet53.conv.74 file if you haven't already (commented)\n",
        "#!wget https://pjreddie.com/media/files/darknet53.conv.74\n",
        "\n",
        "import os.path\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/gdrive'):\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "DARKNET_DIR = '/content/darknet/'\n",
        "DRIVE_DIR = '/content/gdrive/My Drive/PentaKey/mlYOLO/darknet53.conv.74' # adjust path in your Google Drive, or keep it default\n",
        "\n",
        "# Copy the darknet53.conv.74 file from Google Drive to the local directory\n",
        "shutil.copy(DRIVE_DIR, DARKNET_DIR)\n",
        "\n",
        "# Print a message indicating the location where convolutional layers were saved\n",
        "print('Saved convolutional layers to local space at: ' + DARKNET_DIR)"
      ],
      "metadata": {
        "id": "bEVZY7Gh9PdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 - Start the training\n",
        "\n",
        "It will take a long time to complete...\n",
        "\n",
        "Note: If during the training you see NaN values for avg (loss) field then the training will go wrong, but if NaN is found elsewhere then training will go well.\n",
        "\n",
        "- file yolo-obj_last.weights will be saved to the darknet/backup for each 100 iterations\n",
        "- file yolo-obj_xxxx.weights will be saved to the darknet/backup for each 1000 iterations\n",
        "- After each 100 iterations, if you want, you can stop and later start training from this point. For example, after 2000 iterations you can stop training, and later just start training using: darknet detector train data/obj.data yolov3.cfg backup/yolo-obj_2000.weights"
      ],
      "metadata": {
        "id": "HyNN1XRY8avr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List the contents of the current directory\n",
        "!ls\n",
        "\n",
        "# Copy the yolov3-spp_final.weights file from Google Drive to the cfg/ directory\n",
        "shutil.copy(\"/content/gdrive/My Drive/PentaKey/PentaKey/yolov3-spp_final.weights\", \"/content/darknet/cfg/\")\n",
        "\n",
        "# Copy the yolov3-spp_final.weights file from Google Drive to the current directory\n",
        "shutil.copy(\"/content/gdrive/My Drive/PentaKey/PentaKey/yolov3-spp_final.weights\", \"/content/\")\n",
        "\n",
        "# Copy the darknet53.conv.74 file from Google Drive to the current directory\n",
        "shutil.copy(\"/content/gdrive/My Drive/PentaKey/mlYOLO/darknet53.conv.74\", \"/content/\")\n",
        "\n",
        "# Train a YOLOv3-SPP model using the specified configuration and weights\n",
        "# Use this line to retrain your previous saved weights\n",
        "!./darknet detector train data/obj.data cfg/yolov3-spp.cfg /content/yolov3-spp_final.weights -dont_show"
      ],
      "metadata": {
        "id": "zHA_j5lZ8sei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6 - Dump Model to drive (Optional)\n",
        "Once you have trained your model, you can save them to your Google drive. So that next time, you don't need to retrain."
      ],
      "metadata": {
        "id": "bVxLnPF68bur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if Google Drive is mounted; if not, mount it\n",
        "if not os.path.exists('/content/gdrive'):\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "# Define the source path for the YOLOv3-SPP backup weights\n",
        "YOLO_BACKUP = '/content/darknet/backup/yolov3-spp_last.weights' # Adjust the backup file name or keep it default\n",
        "\n",
        "# Define the destination directory in Google Drive\n",
        "DRIVE_DIR = '/content/gdrive/My Drive/mlYOLO/' # Adjust the path in your Google Drive, or keep it default\n",
        "\n",
        "# Copy the YOLOv3-SPP backup weights to Google Drive\n",
        "shutil.copy(YOLO_BACKUP, DRIVE_DIR)\n",
        "\n",
        "# Print a message indicating the location where the training data was saved\n",
        "print('Saved training data to drive at: ' + DRIVE_DIR)"
      ],
      "metadata": {
        "id": "ffCixZ8d85FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 - Importing the weights"
      ],
      "metadata": {
        "id": "CbTzs2wt88SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Check if Google Drive is mounted; if not, mount it\n",
        "if not os.path.exists('/content/gdrive'):\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "# Define the source file path in Google Drive\n",
        "DRIVE_DIR = '/content/gdrive/My Drive/ASMC/PentaKey/PentaKey/yolov3-spp_final.weights' # Adjust the path in your Google Drive, or keep it default\n",
        "\n",
        "# Define the destination directory in the local file system\n",
        "YOLO_BACKUP = '/content/darknet/backup/' # Adjust the backup file name or keep it default\n",
        "\n",
        "# Copy the file from Google Drive to the local directory\n",
        "shutil.copy(DRIVE_DIR, YOLO_BACKUP)\n",
        "\n",
        "# Print a message indicating the location where the training data was saved\n",
        "print('Saved training data to the local directory at: ' + YOLO_BACKUP)"
      ],
      "metadata": {
        "id": "u6m2RZXrLSGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mAP (mean Average Precision) for the YOLOv3-SPP model\n",
        "# - `data/obj.data`: Path to the data file\n",
        "# - `cfg/yolov3-spp.cfg`: Path to the configuration file\n",
        "# - `backup/yolov3-spp_final.weights`: Path to the weight file\n",
        "\n",
        "!./darknet detector map data/obj.data cfg/yolov3-spp.cfg backup/yolov3-spp_final.weights"
      ],
      "metadata": {
        "id": "WwQeqTYvLTLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8 - Predict"
      ],
      "metadata": {
        "id": "UyJB4PHE-xpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform object detection using YOLOv3-SPP model\n",
        "# - `data/obj.data`: Path to the data file\n",
        "# - `cfg/yolov3-spp.cfg`: Path to the configuration file\n",
        "# - `/content/gdrive/MyDrive/ASMC/PentaKey/PentaKey/yolov3-spp_final.weights`: Path to the weight file\n",
        "# - `data/img/fratelli_d_italia.png`: Path to the input image\n",
        "# - `-thresh 0.1`: Detection threshold set to 0.1\n",
        "# - `-out risultato.json`: Output results to a file named \"risultato.json\"\n",
        "\n",
        "!./darknet detector test data/obj.data cfg/yolov3-spp.cfg /content/gdrive/MyDrive/ASMC/PentaKey/PentaKey/yolov3-spp_final.weights data/img/jingle_bell.jpg -thresh 0.1 -out risultato.json"
      ],
      "metadata": {
        "id": "YBGIkhPmMpkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the \"risultato.json\" file to your local machine\n",
        "from google.colab import files\n",
        "\n",
        "files.download('risultato.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "StMo4ths8ww_",
        "outputId": "01cec99d-b0f3-48b6-e3e0-fe4e35c76dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fab8090b-4e2c-474b-82e3-b0e6aedecc9f\", \"risultato.json\", 29896)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1-8sY_oJlhYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9 - Display the results\n",
        "Show the JPEG with the prediction made (with each prediction the file predictions.jpg is changed)"
      ],
      "metadata": {
        "id": "mh10G9Xx_E6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "\n",
        "# Define the display_image function\n",
        "def display_image(file_path='/content/darknet/predictions.jpg'):\n",
        "    # Check if the file exists at the specified path\n",
        "    if os.path.exists(file_path):\n",
        "        # Read the image using OpenCV\n",
        "        img = cv2.imread(file_path)\n",
        "\n",
        "        # Convert BGR to RGB color format for Matplotlib\n",
        "        show_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Display the image using Matplotlib\n",
        "        plt.imshow(show_img)\n",
        "    else:\n",
        "        print('Failed to open file')\n",
        "\n",
        "# Call the display_image function\n",
        "display_image()"
      ],
      "metadata": {
        "id": "px2byRHbMzGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 - Converting it all to MusicXML\n",
        "To effectively perform this task, please refer to the project's repository at https://github.com/blazQ/dolores."
      ],
      "metadata": {
        "id": "Z2gIcr07SB0L"
      }
    }
  ]
}